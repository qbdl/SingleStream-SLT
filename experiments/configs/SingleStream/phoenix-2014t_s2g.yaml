task: S2G
data:
  input_data: videos 
  input_streams:
    - rgb
  zip_file: data/phoenix-2014t/phoenix-2014t-videos.zip
  dev: data/phoenix-2014t/phoenix-2014t_cleaned.dev
  test: data/phoenix-2014t/phoenix-2014t_cleaned.test
  train: data/phoenix-2014t/phoenix-2014t_cleaned.train
  dataset_name: phoenix-2014t
  level: word #word or char
  txt_lowercase: true
  max_sent_length: 400
  transform_cfg:
    img_size: 224
    aug_hflip: false
    color_jitter: true
    bottom_area: 0.7
    center_crop_size: 224 
    center_crop: True
    randomcrop_threshold: 1
    aspect_ratio_min: 0.75
    aspect_ratio_max: 1.3
    temporal_augmentation:
      tmin: 0.5
      tmax: 1.5
testing:
  cfg:
    recognition:
      beam_size: 5
training:
  overwrite: True
  model_dir: experiments/outputs/SingleStream/phoenix-2014t_s2g
  shuffle: True
  num_workers: 4
  batch_size: 1 
  total_epoch: 40
  keep_last_ckpts: 5
  validation: 
    unit: epoch
    freq: 1
    cfg:
      recognition:
        beam_size: 1
  optimization:
    optimizer: Adam
    learning_rate:
      default: 1.0e-3
    weight_decay: 0.001
    betas:
    - 0.9
    - 0.998
    scheduler: cosineannealing
    t_max: 40
model:
  RecognitionNetwork:
    GlossTokenizer:
      gloss2id_file: data/phoenix-2014t/gloss2ids_old.pkl
    s3d:
      pretrained_ckpt: pretrained_models/s3ds_glosscls_ckpt 
      use_block: 4
      freeze_block: 1
    visual_head:
      input_size: 832
      hidden_size: 512
      ff_size: 2048 
      pe: True 
      ff_kernelsize:
        - 3
        - 3




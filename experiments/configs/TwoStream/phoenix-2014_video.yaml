task: S2G
data:
  input_data: video 
  input_streams:
    - rgb
  zip_file: data/phoenix-2014/phoenix-2014-videos.zip
  train: data/phoenix-2014/phoenix-2014.train
  dev: data/phoenix-2014/phoenix-2014.dev
  test: data/phoenix-2014/phoenix-2014.test
  dataset_name: phoenix-2014 
  level: word #word or char
  txt_lowercase: true
  max_sent_length: 400
  transform_cfg:
    img_size: 224
    color_jitter: true
    bottom_area: 0.7 
    center_crop_size: 224 
    center_crop: False
    randomcrop_threshold: 1
    aspect_ratio_min: 0.75
    aspect_ratio_max: 1.3
    temporal_augmentation:
      tmin: 0.5
      tmax: 1.5
testing:
  cfg:
    recognition:
      beam_size: 5
training:
  overwrite: True
  model_dir: experiments/outputs/TwoStream/phoenix-2014_video
  shuffle: True
  num_workers: 4
  batch_size: 1 
  total_epoch: 40
  keep_last_ckpts: 5
  validation: 
    unit: epoch
    freq: 1
    cfg:
      recognition:
        beam_size: 1
  optimization:
    optimizer: Adam
    learning_rate:
      default: 1.0e-3
    weight_decay: 0.001
    betas:
    - 0.9
    - 0.998
    scheduler: cosineannealing
    t_max: 40
model:
  RecognitionNetwork:
    GlossTokenizer:
      lower_case: False
      gloss2id_file: data/phoenix-2014/gloss2ids.pkl
    s3d:
      pretrained_ckpt: pretrained_models/s3ds_actioncls_ckpt #from K400
      use_block: 4
      freeze_block: 1
    keypoint_s3d:
      in_channel: 0 # placeholder
      pretrained_ckpt: pretrained_models/s3ds_actioncls_ckpt #from K400
      use_block: 4
      freeze_block: 0
    heatmap_cfg:
      raw_size:
        - 260
        - 210 
      input_size: 112
      sigma: 1
    fuse_method: empty
    visual_head:
      input_size: 832
      hidden_size: 512
      ff_size: 2048 
      pe: True
      ff_kernelsize:
        - 3
        - 3




